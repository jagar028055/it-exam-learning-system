# ITè©¦é¨“å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  - æŠ€è¡“è¦ä»¶ãƒ»åˆ¶ç´„äº‹é …å®šç¾©æ›¸

**ç­–å®šæ—¥**: 2025å¹´7æœˆ30æ—¥
**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: æƒ…å ±æŠ€è¡“è€…è©¦é¨“å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  åŒ…æ‹¬çš„æ”¹å–„
**å¯¾è±¡**: æŠ€è¡“è¦ä»¶ãƒ»åˆ¶ç´„äº‹é …è©³ç´°å®šç¾©

---

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¦ä»¶

### ç¾çŠ¶ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è©•ä¾¡ã¨æ”¹å–„æ–¹é‡

**ç¾çŠ¶**:
```
Frontend: Jinja2 Templates + Bootstrap + JavaScript
Backend: Flask + Blueprint Pattern + Service Layer
Database: SQLite + Optimized Queries + Caching
Deployment: Render + Gunicorn + GitHub Actions
```

**è©•ä¾¡**:
âœ… **å„ªç§€ãªç‚¹**: 
- é©åˆ‡ãªãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ†é›¢
- ã‚µãƒ¼ãƒ“ã‚¹æŒ‡å‘ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåŒ–

âš ï¸ **æ”¹å–„ç‚¹**:
- ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®é™ç•Œ
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ©Ÿèƒ½ã®æ¬ å¦‚
- é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿åˆ†ææ©Ÿèƒ½ã®ä¸è¶³

### ğŸ¯ ç›®æ¨™ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph TB
    subgraph "Frontend Layer"
        UI[Progressive Web App]
        WS[WebSocket Client]
        SW[Service Worker]
    end
    
    subgraph "API Gateway"
        GW[Rate Limiting + Auth]
        CACHE[Redis Cache]
    end
    
    subgraph "Application Layer"
        API[REST API Service]
        RT[Real-time Service]
        ML[ML Analysis Service]
        BG[Background Jobs]
    end
    
    subgraph "Data Layer"
        PG[(PostgreSQL)]
        ES[(Elasticsearch)]
        S3[(File Storage)]
        MQ[Message Queue]
    end
    
    UI --> GW
    WS --> RT
    GW --> API
    API --> PG
    ML --> ES
    BG --> MQ
```

---

## ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¦ä»¶

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç§»è¡Œæˆ¦ç•¥

#### **Phase 1: SQLiteæ‹¡å¼µï¼ˆå³åº§å®Ÿè¡Œå¯èƒ½ï¼‰**

```sql
-- æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã®æœ€é©åŒ–
CREATE INDEX idx_questions_category ON questions(category, difficulty);
CREATE INDEX idx_learning_records_session ON learning_records(session_id, attempt_date);
CREATE INDEX idx_study_sessions_user_date ON study_sessions(user_id, start_time);

-- æ–°æ©Ÿèƒ½å¯¾å¿œãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE user_profiles (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id TEXT UNIQUE NOT NULL,
    target_exam TEXT DEFAULT 'FE', 
    target_date DATE,
    daily_goal INTEGER DEFAULT 20,
    preferred_difficulty INTEGER DEFAULT 2,
    learning_style TEXT DEFAULT 'balanced',
    timezone TEXT DEFAULT 'Asia/Tokyo',
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE learning_insights (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id TEXT NOT NULL,
    insight_type TEXT NOT NULL, -- 'weakness', 'strength', 'recommendation'
    content TEXT NOT NULL,
    confidence_score REAL DEFAULT 0.5,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    expires_at DATETIME
);

CREATE TABLE gamification_data (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id TEXT NOT NULL,
    points INTEGER DEFAULT 0,
    level INTEGER DEFAULT 1,
    streak_days INTEGER DEFAULT 0,
    achievements TEXT, -- JSONé…åˆ—
    last_activity DATETIME,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

#### **Phase 2: PostgreSQLç§»è¡Œï¼ˆã‚¹ã‚±ãƒ¼ãƒ«æ™‚ï¼‰**

```sql
-- æœ¬æ ¼é‹ç”¨æ™‚ã®PostgreSQLè¨­è¨ˆ
CREATE TABLE questions (
    id SERIAL PRIMARY KEY,
    question_text TEXT NOT NULL,
    choices JSONB NOT NULL,
    correct_answer INTEGER NOT NULL,
    category VARCHAR(100) NOT NULL,
    subcategory VARCHAR(100),
    difficulty_level INTEGER CHECK (difficulty_level BETWEEN 1 AND 5),
    importance_score REAL DEFAULT 1.0,
    year INTEGER,
    exam_type VARCHAR(10) DEFAULT 'FE',
    explanation TEXT,
    keywords TEXT[], -- PostgreSQLé…åˆ—å‹
    related_questions INTEGER[],
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- é«˜æ€§èƒ½ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX CONCURRENTLY idx_questions_full_text ON questions 
USING GIN (to_tsvector('japanese', question_text || ' ' || explanation));

CREATE INDEX CONCURRENTLY idx_questions_composite ON questions 
(exam_type, category, difficulty_level) 
INCLUDE (id, importance_score);
```

### ğŸ“Š åˆ†æãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ

```sql
-- å­¦ç¿’åˆ†æç”¨ãƒãƒ†ãƒªã‚¢ãƒ©ã‚¤ã‚ºãƒ‰ãƒ“ãƒ¥ãƒ¼
CREATE MATERIALIZED VIEW learning_analytics AS
SELECT 
    DATE_TRUNC('day', lr.attempt_date) as learning_date,
    lr.question_id,
    q.category,
    q.difficulty_level,
    COUNT(*) as attempt_count,
    AVG(CASE WHEN lr.is_correct THEN 1.0 ELSE 0.0 END) as accuracy_rate,
    AVG(lr.response_time) as avg_response_time,
    COUNT(DISTINCT lr.session_id) as session_count
FROM learning_records lr
JOIN questions q ON lr.question_id = q.id
GROUP BY 1, 2, 3, 4;

-- å®šæœŸæ›´æ–°ã‚¸ãƒ§ãƒ–
CREATE OR REPLACE FUNCTION refresh_learning_analytics()
RETURNS void AS $$
BEGIN
    REFRESH MATERIALIZED VIEW CONCURRENTLY learning_analytics;
END;
$$ LANGUAGE plpgsql;
```

---

## ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶

### ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥

#### **Multi-layer Caching**

```python
# L1: Application Cache (Flask-Caching)
from flask_caching import Cache

cache_config = {
    'CACHE_TYPE': 'RedisCache',
    'CACHE_REDIS_URL': 'redis://localhost:6379/0',
    'CACHE_DEFAULT_TIMEOUT': 300
}

# L2: Database Query Cache
class OptimizedQuestionService:
    @cache.memoize(timeout=3600)
    def get_questions_by_category(self, category: str, limit: int = 50):
        """ã‚«ãƒ†ã‚´ãƒªåˆ¥å•é¡Œå–å¾—ï¼ˆ1æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰"""
        pass
    
    @cache.memoize(timeout=300) 
    def get_user_recommendations(self, user_id: str):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨å¥¨å•é¡Œï¼ˆ5åˆ†ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰"""
        pass

# L3: CDN Cache (Static Assets)
# nginx.conf
location /static/ {
    expires 1y;
    add_header Cache-Control "public, immutable";
}
```

#### **Database Connection Pooling**

```python
# SQLAlchemy Connection Poolæœ€é©åŒ–
from sqlalchemy import create_engine
from sqlalchemy.pool import StaticPool

engine = create_engine(
    'postgresql://user:pass@host/db',
    poolclass=StaticPool,
    pool_size=20,
    max_overflow=30,
    pool_timeout=30,
    pool_recycle=3600,
    echo=False
)
```

### ğŸ“ˆ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£å¯¾å¿œ

#### **Horizontal Scaling Strategy**

```yaml
# Docker Compose for Multi-Service
version: '3.8'
services:
  web:
    build: .
    ports:
      - "8000-8003:8000"
    replicas: 4
    environment:
      - DATABASE_URL=postgresql://...
      - REDIS_URL=redis://redis:6379
      
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - web
      
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
      
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: learning_system
    volumes:
      - postgres_data:/var/lib/postgresql/data
```

---

## ğŸ¤– æ©Ÿæ¢°å­¦ç¿’è¦ä»¶

### å­¦ç¿’åˆ†æã‚¨ãƒ³ã‚¸ãƒ³

#### **Recommendation Algorithm**

```python
import numpy as np
import pandas as pd
from sklearn.collaborative_filtering import NMF
from sklearn.metrics.pairwise import cosine_similarity

class IntelligentRecommendationEngine:
    def __init__(self):
        self.model = NMF(n_components=50, random_state=42)
        self.user_item_matrix = None
        
    def train_model(self, learning_records: pd.DataFrame):
        """å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼-å•é¡Œãƒãƒˆãƒªãƒƒã‚¯ã‚¹ä½œæˆ
        self.user_item_matrix = learning_records.pivot_table(
            index='user_id', 
            columns='question_id', 
            values='is_correct',
            fill_value=0
        )
        
        # éè² å€¤è¡Œåˆ—åˆ†è§£
        self.model.fit(self.user_item_matrix)
        
    def recommend_questions(self, user_id: str, n_recommendations: int = 10):
        """å€‹äººåŒ–ã•ã‚ŒãŸå•é¡Œæ¨å¥¨"""
        if user_id not in self.user_item_matrix.index:
            return self._cold_start_recommendations(n_recommendations)
            
        user_idx = self.user_item_matrix.index.get_loc(user_id)
        user_factors = self.model.transform(self.user_item_matrix.iloc[user_idx:user_idx+1])
        
        # æ¨å¥¨ã‚¹ã‚³ã‚¢è¨ˆç®—
        item_factors = self.model.components_
        scores = np.dot(user_factors, item_factors)[0]
        
        # æœªå›ç­”å•é¡Œã‹ã‚‰æ¨å¥¨
        answered_questions = self.user_item_matrix.iloc[user_idx].nonzero()[0]
        unanswered_mask = np.ones(len(scores), dtype=bool)
        unanswered_mask[answered_questions] = False
        
        top_indices = np.argsort(scores[unanswered_mask])[-n_recommendations:]
        return self.user_item_matrix.columns[unanswered_mask][top_indices]
```

#### **Adaptive Difficulty System**

```python
class AdaptiveDifficultyEngine:
    def __init__(self):
        self.elo_k_factor = 32
        self.default_rating = 1200
        
    def calculate_question_difficulty(self, question_id: int) -> float:
        """å•é¡Œã®é›£æ˜“åº¦ã‚’Eloãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã§è¨ˆç®—"""
        records = self.get_question_records(question_id)
        
        if not records:
            return self.default_rating
            
        # Eloãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ é©ç”¨
        total_rating = 0
        total_weight = 0
        
        for record in records:
            user_skill = self.get_user_skill_level(record.user_id)
            expected_score = 1 / (1 + 10**((self.default_rating - user_skill) / 400))
            actual_score = 1 if record.is_correct else 0
            
            # é‡ã¿ä»˜ã‘ï¼ˆæœ€è¿‘ã®è¨˜éŒ²ã»ã©é‡è¦ï¼‰
            days_ago = (datetime.now() - record.attempt_date).days
            weight = np.exp(-days_ago / 30)  # 30æ—¥ã§åŠæ¸›
            
            total_rating += weight * (self.default_rating + self.elo_k_factor * (actual_score - expected_score))
            total_weight += weight
            
        return total_rating / total_weight if total_weight > 0 else self.default_rating
```

---

## ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶

### èªè¨¼ãƒ»èªå¯ã‚·ã‚¹ãƒ†ãƒ 

#### **Multi-Factor Authentication**

```python
from flask_jwt_extended import JWTManager
import pyotp
import qrcode

class SecureAuthSystem:
    def __init__(self, app):
        self.jwt = JWTManager(app)
        
    def generate_2fa_secret(self, user_id: str) -> str:
        """2FAç”¨ç§˜å¯†éµç”Ÿæˆ"""
        secret = pyotp.random_base32()
        
        # QRã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        totp_uri = pyotp.totp.TOTP(secret).provisioning_uri(
            name=user_id,
            issuer_name="IT Exam Learning System"
        )
        
        qr = qrcode.QRCode(version=1, box_size=10, border=5)
        qr.add_data(totp_uri)
        qr.make(fit=True)
        
        return secret, qr.make_image(fill_color="black", back_color="white")
    
    def verify_2fa_token(self, secret: str, token: str) -> bool:
        """2FAãƒˆãƒ¼ã‚¯ãƒ³æ¤œè¨¼"""
        totp = pyotp.TOTP(secret)
        return totp.verify(token, valid_window=1)
```

#### **Data Protection**

```python
from cryptography.fernet import Fernet
import hashlib

class DataProtectionService:
    def __init__(self, encryption_key: bytes):
        self.cipher = Fernet(encryption_key)
        
    def encrypt_personal_data(self, data: str) -> str:
        """å€‹äººæƒ…å ±ã®æš—å·åŒ–"""
        return self.cipher.encrypt(data.encode()).decode()
    
    def decrypt_personal_data(self, encrypted_data: str) -> str:
        """å€‹äººæƒ…å ±ã®å¾©å·åŒ–"""
        return self.cipher.decrypt(encrypted_data.encode()).decode()
    
    def hash_sensitive_data(self, data: str) -> str:
        """æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥åŒ–"""
        return hashlib.sha256(data.encode()).hexdigest()
```

---

## ğŸ“Š ç›£è¦–ãƒ»ãƒ­ã‚°è¦ä»¶

### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç›£è¦–

```python
from prometheus_flask_exporter import PrometheusMetrics
import structlog

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
metrics = PrometheusMetrics(app)

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
learning_session_counter = Counter(
    'learning_sessions_total',
    'Total number of learning sessions',
    ['exam_type', 'study_mode']
)

question_response_time = Histogram(
    'question_response_seconds',
    'Time spent answering questions',
    ['category', 'difficulty']
)

# æ§‹é€ åŒ–ãƒ­ã‚°
logger = structlog.get_logger()

@app.route('/api/questions/<int:question_id>/answer', methods=['POST'])
def submit_answer(question_id):
    start_time = time.time()
    
    try:
        # ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯
        result = process_answer(question_id, request.json)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
        response_time = time.time() - start_time
        question_response_time.labels(
            category=result.category,
            difficulty=result.difficulty
        ).observe(response_time)
        
        # ãƒ­ã‚°è¨˜éŒ²
        logger.info(
            "answer_submitted",
            question_id=question_id,
            user_id=get_current_user_id(),
            is_correct=result.is_correct,
            response_time=response_time
        )
        
        return jsonify(result.to_dict())
        
    except Exception as e:
        logger.error(
            "answer_submission_failed",
            question_id=question_id,
            error=str(e),
            traceback=traceback.format_exc()
        )
        raise
```

---

## ğŸ”§ é–‹ç™ºãƒ»é‹ç”¨è¦ä»¶

### CI/CD Pipeline

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production
on:
  push:
    branches: [main]
    
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
      - name: Run tests
        run: |
          pytest --cov=src --cov-report=xml
          flake8 src/
          black --check src/
      - name: Security scan
        run: bandit -r src/
        
  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Deploy to Render
        run: |
          curl -X POST ${{ secrets.RENDER_DEPLOY_HOOK }}
```

### Infrastructure as Code

```yaml
# docker-compose.production.yml
version: '3.8'
services:
  web:
    build:
      context: .
      dockerfile: Dockerfile.prod
    environment:
      - FLASK_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.prod.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - web
      
  redis:
    image: redis:alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
      
volumes:
  redis_data:
```

---

## ğŸ¯ åˆ¶ç´„äº‹é …ãƒ»ãƒªã‚¹ã‚¯

### æŠ€è¡“çš„åˆ¶ç´„
- **ç¾åœ¨ã®Renderç’°å¢ƒ**: ãƒ¡ãƒ¢ãƒª512MBã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åˆ¶é™
- **SQLiteåˆ¶é™**: åŒæ™‚æ›¸ãè¾¼ã¿åˆ¶é™ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºä¸Šé™
- **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰**: SPAåŒ–ã›ãšã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ç¶­æŒ

### é‹ç”¨åˆ¶ç´„
- **äºˆç®—åˆ¶é™**: æœˆé¡$50ä»¥ä¸‹ã®ã‚¤ãƒ³ãƒ•ãƒ©è²»ç”¨
- **é‹ç”¨ä½“åˆ¶**: åŸºæœ¬çš„ã«è‡ªå‹•åŒ–ã€æœ€å°é™ã®æ‰‹å‹•é‹ç”¨
- **ãƒ‡ãƒ¼ã‚¿ç§»è¡Œ**: ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ æœ€å°åŒ–

### ãƒªã‚¹ã‚¯è©•ä¾¡ãƒ»å¯¾ç­–

| ãƒªã‚¹ã‚¯ | ç¢ºç‡ | å½±éŸ¿ | å¯¾ç­– |
|--------|------|------|------|
| ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ä¸è¶³ | ä¸­ | é«˜ | PostgreSQLç§»è¡Œè¨ˆç”» |
| ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ | ä½ | é«˜ | å®šæœŸã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ» |
| ãƒ‡ãƒ¼ã‚¿ç ´æ | ä½ | é«˜ | è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— + ãƒ†ã‚¹ãƒˆ |
| ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ– | ä¸­ | ä¸­ | ç›£è¦–ã‚¢ãƒ©ãƒ¼ãƒˆ + æœ€é©åŒ– |

---

## ğŸ“‹ å®Ÿè£…ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³

### Phase 1: åŸºç›¤å¼·åŒ–ï¼ˆ2-3é€±é–“ï¼‰
- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ‹¡å¼µãƒ»æœ€é©åŒ–
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ å°å…¥
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–
- [ ] ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰

### Phase 2: é«˜åº¦æ©Ÿèƒ½ï¼ˆ4-6é€±é–“ï¼‰
- [ ] MLæ¨å¥¨ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…
- [ ] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ©Ÿèƒ½è¿½åŠ 
- [ ] é«˜åº¦åˆ†ææ©Ÿèƒ½
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### Phase 3: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆå¿…è¦æ™‚ï¼‰
- [ ] PostgreSQLç§»è¡Œ
- [ ] ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–
- [ ] Kuberneteså¯¾å¿œ
- [ ] CDNãƒ»è² è·åˆ†æ•£

---

ã“ã®æŠ€è¡“è¦ä»¶ã«åŸºã¥ãã€ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’æ®µéšçš„ã«é€²åŒ–ã•ã›ã€
é«˜æ€§èƒ½ãƒ»é«˜å¯ç”¨æ€§ãƒ»é«˜ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãªå­¦ç¿’ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚