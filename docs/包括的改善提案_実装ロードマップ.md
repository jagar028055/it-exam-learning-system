# ITè©¦é¨“å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  - å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ãƒ»å„ªå…ˆåº¦å®šç¾©æ›¸

**ç­–å®šæ—¥**: 2025å¹´7æœˆ30æ—¥
**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: æƒ…å ±æŠ€è¡“è€…è©¦é¨“å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  åŒ…æ‹¬çš„æ”¹å–„
**å¯¾è±¡**: å®Ÿè£…å„ªå…ˆåº¦ãƒ»ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ãƒ»å®Ÿè¡Œè¨ˆç”»

---

## ğŸ¯ å®Ÿè£…æˆ¦ç•¥æ¦‚è¦

### æ®µéšçš„å®Ÿè£…ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

**Phase 1**: åŸºç›¤å¼·åŒ–ï¼ˆå³åº§å®Ÿè¡Œå¯èƒ½ï¼‰
**Phase 2**: é«˜åº¦æ©Ÿèƒ½å®Ÿè£…ï¼ˆä¸­æœŸçš„æŠ•è³‡ï¼‰
**Phase 3**: æ¬¡ä¸–ä»£ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼ˆé•·æœŸçš„ãƒ“ã‚¸ãƒ§ãƒ³ï¼‰

### å®Ÿè£…åˆ¤æ–­åŸºæº–

| è©•ä¾¡è»¸ | é‡ã¿ | èª¬æ˜ |
|--------|------|------|
| **ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¾¡å€¤** | 40% | å­¦ç¿’åŠ¹æœãƒ»æº€è¶³åº¦ã¸ã®ç›´æ¥çš„å½±éŸ¿ |
| **æŠ€è¡“çš„å®Ÿç¾æ€§** | 25% | ç¾åœ¨ã®ã‚¹ã‚­ãƒ«ãƒ»ãƒªã‚½ãƒ¼ã‚¹ã§ã®å®Ÿè£…å¯èƒ½æ€§ |
| **æŠ•è³‡å¯¾åŠ¹æœ** | 20% | é–‹ç™ºã‚³ã‚¹ãƒˆå¯¾æœŸå¾…åŠ¹æœ |
| **ãƒªã‚¹ã‚¯** | 15% | æŠ€è¡“çš„ãƒ»é‹ç”¨çš„ãƒªã‚¹ã‚¯ã®ä½ã• |

---

## ğŸ“‹ Phase 1: åŸºç›¤å¼·åŒ–ï¼ˆæœ€å„ªå…ˆ - 4-6é€±é–“ï¼‰

### ğŸ”´ ç·Šæ€¥åº¦ï¼šæœ€é«˜ï¼ˆå³åº§é–‹å§‹ï¼‰

#### **1.1 å•é¡Œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ‹¡å……**
**å„ªå…ˆåº¦**: â˜…â˜…â˜…â˜…â˜… | **æœŸé–“**: 1-2é€±é–“ | **æŠ•è³‡**: ä½

**èƒŒæ™¯**: ç¾åœ¨2å•ã®ã¿ â†’ å®Ÿç”¨ãƒ¬ãƒ™ãƒ«1,000å•ä»¥ä¸Šå¿…è¦

**å®Ÿè£…å†…å®¹**:
```python
# data_collector/ipa_scraper.py
import requests
from bs4 import BeautifulSoup
import json
from pathlib import Path

class IPADataCollector:
    def __init__(self):
        self.base_url = "https://www.jitec.ipa.go.jp"
        self.session = requests.Session()
        
    def collect_past_exam_data(self, exam_type: str, years: list) -> list:
        """éå»å•ãƒ‡ãƒ¼ã‚¿åé›†"""
        questions = []
        
        for year in years:
            try:
                # å•é¡ŒPDFå–å¾—
                pdf_url = f"{self.base_url}/1_11seido/s1_doc/{exam_type}{year}.pdf"
                pdf_content = self.download_pdf(pdf_url)
                
                # è§£ç­”PDFå–å¾—  
                answer_url = f"{self.base_url}/1_11seido/s1_doc/{exam_type}{year}_a.pdf"
                answer_content = self.download_pdf(answer_url)
                
                # PDFã‹ã‚‰å•é¡ŒæŠ½å‡º
                extracted_questions = self.extract_questions_from_pdf(
                    pdf_content, answer_content, exam_type, year
                )
                
                questions.extend(extracted_questions)
                
            except Exception as e:
                print(f"Error collecting {exam_type} {year}: {e}")
                continue
                
        return questions
    
    def extract_questions_from_pdf(self, question_pdf, answer_pdf, exam_type, year):
        """PDFã‹ã‚‰æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"""
        # pdfplumberã‚’ä½¿ç”¨ã—ãŸé«˜ç²¾åº¦æŠ½å‡º
        import pdfplumber
        
        questions = []
        
        with pdfplumber.open(question_pdf) as pdf:
            for page in pdf.pages:
                text = page.extract_text()
                
                # å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜
                question_blocks = self.parse_question_blocks(text)
                
                for block in question_blocks:
                    question_data = {
                        'question_text': block['text'],
                        'choices': block['choices'],
                        'exam_type': exam_type,
                        'year': year,
                        'category': self.categorize_question(block['text']),
                        'difficulty': self.estimate_difficulty(block['text']),
                        'source': f"IPA {exam_type} {year}"
                    }
                    
                    # æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒãƒ³ã‚°
                    correct_answer = self.match_correct_answer(
                        answer_pdf, block['question_id']
                    )
                    question_data['correct_answer'] = correct_answer
                    
                    questions.append(question_data)
        
        return questions

# å®Ÿè£…ã‚¿ã‚¹ã‚¯
TASKS = [
    "âœ… IPAã‚µã‚¤ãƒˆæ§‹é€ èª¿æŸ»ãƒ»ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­è¨ˆ",
    "âœ… PDFè§£æã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè£…ï¼ˆpdfplumber + æ­£è¦è¡¨ç¾ï¼‰", 
    "âœ… å•é¡Œåˆ†é¡ãƒ»é›£æ˜“åº¦æ¨å®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ",
    "âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸€æ‹¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ©Ÿèƒ½",
    "âœ… é‡è¤‡æ¤œå‡ºãƒ»ãƒãƒ¼ã‚¸æ©Ÿèƒ½",
    "âœ… ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ãƒ»æ¤œè¨¼"
]
```

**æœŸå¾…åŠ¹æœ**:
- åŸºæœ¬æƒ…å ±æŠ€è¡“è€…: 800å•ä»¥ä¸Š
- å¿œç”¨æƒ…å ±æŠ€è¡“è€…: 600å•ä»¥ä¸Š  
- ITãƒ‘ã‚¹ãƒãƒ¼ãƒˆ: 500å•ä»¥ä¸Š
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ: 400å•ä»¥ä¸Š

#### **1.2 å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³åŸºç›¤å®Ÿè£…**
**å„ªå…ˆåº¦**: â˜…â˜…â˜…â˜…â˜… | **æœŸé–“**: 2-3é€±é–“ | **æŠ•è³‡**: ä¸­

**å®Ÿè£…å†…å®¹**:
```python
# learning_engine/adaptive_engine.py
class AdaptiveLearningEngine:
    def __init__(self):
        self.skill_estimator = SkillEstimator()
        self.question_selector = QuestionSelector()
        self.progress_tracker = ProgressTracker()
    
    def generate_study_session(self, user_id: int, preferences: dict) -> StudySession:
        """å€‹äººæœ€é©åŒ–ã•ã‚ŒãŸå­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        
        # 1. ç¾åœ¨ã®ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«æ¨å®š
        skill_profile = self.skill_estimator.estimate_user_skills(user_id)
        
        # 2. å­¦ç¿’ç›®æ¨™åˆ†æ
        target_exam = preferences.get('target_exam', 'FE')
        target_date = preferences.get('target_date')
        daily_time = preferences.get('daily_minutes', 30)
        
        # 3. å¼±ç‚¹åˆ†é‡ç‰¹å®š
        weak_areas = self.identify_weak_areas(skill_profile)
        
        # 4. æœ€é©å•é¡Œé¸å‡º
        questions = self.question_selector.select_optimal_questions(
            skill_profile=skill_profile,
            weak_areas=weak_areas,
            target_exam=target_exam,
            session_length=daily_time
        )
        
        # 5. ã‚»ãƒƒã‚·ãƒ§ãƒ³æ§‹æˆ
        session = StudySession(
            user_id=user_id,
            questions=questions,
            estimated_duration=self.estimate_session_duration(questions),
            learning_objectives=self.define_objectives(weak_areas),
            adaptive_settings=self.configure_adaptivity(skill_profile)
        )
        
        return session
    
    def process_answer(self, session_id: int, question_id: int, 
                      user_answer: int, response_time: int) -> AnswerFeedback:
        """å›ç­”å‡¦ç†ã¨å³åº§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"""
        
        question = self.get_question(question_id)
        is_correct = (user_answer == question.correct_answer)
        
        # ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«æ›´æ–°ï¼ˆEloãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼‰
        self.skill_estimator.update_skill_rating(
            user_id=session.user_id,
            question_difficulty=question.difficulty_rating,
            is_correct=is_correct,
            response_time=response_time
        )
        
        # æ¬¡å•é¡Œã®å‹•çš„èª¿æ•´
        next_question = self.question_selector.select_next_question(
            session_id=session_id,
            previous_performance=is_correct,
            current_skill=self.skill_estimator.get_current_skill(session.user_id)
        )
        
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ
        feedback = AnswerFeedback(
            is_correct=is_correct,
            explanation=question.explanation,
            skill_impact=self.calculate_skill_impact(is_correct, question),
            next_question=next_question,
            progress_update=self.get_progress_update(session_id)
        )
        
        return feedback

# å®Ÿè£…ã‚¿ã‚¹ã‚¯
IMPLEMENTATION_TASKS = [
    "âœ… Eloãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ãƒ»ã‚¹ã‚­ãƒ«æ¨å®šã‚·ã‚¹ãƒ†ãƒ ",
    "âœ… é–“éš”åå¾©å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆSM-2æ”¹è‰¯ç‰ˆï¼‰",
    "âœ… å¼±ç‚¹åˆ†é‡è‡ªå‹•è­˜åˆ¥ãƒ»é‡ã¿ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ ", 
    "âœ… å•é¡Œé›£æ˜“åº¦å‹•çš„èª¿æ•´æ©Ÿèƒ½",
    "âœ… å­¦ç¿’åŠ¹æœæ¸¬å®šãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—",
    "âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶™ç¶šãƒ»ä¸­æ–­ãƒ»å¾©å¸°æ©Ÿèƒ½"
]
```

#### **1.3 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**
**å„ªå…ˆåº¦**: â˜…â˜…â˜…â˜…â˜† | **æœŸé–“**: 2é€±é–“ | **æŠ•è³‡**: ä¸­

**å®Ÿè£…å†…å®¹**:
```python
# analytics/real_time_dashboard.py
from flask_socketio import SocketIO, emit
import json
from datetime import datetime, timedelta

class RealTimeDashboard:
    def __init__(self, app, socketio):
        self.app = app
        self.socketio = socketio
        self.active_sessions = {}
        
    def track_learning_session(self, session_id: int, user_id: int):
        """å­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³è¿½è·¡é–‹å§‹"""
        self.active_sessions[session_id] = {
            'user_id': user_id,
            'start_time': datetime.now(),
            'questions_answered': 0,
            'correct_answers': 0,
            'current_streak': 0,
            'peak_response_time': 0
        }
        
        # WebSocketçµŒç”±ã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°
        self.socketio.emit('session_started', {
            'session_id': session_id,
            'timestamp': datetime.now().isoformat()
        }, room=f'user_{user_id}')
    
    def update_session_progress(self, session_id: int, answer_data: dict):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—æ›´æ–°"""
        if session_id not in self.active_sessions:
            return
            
        session = self.active_sessions[session_id]
        session['questions_answered'] += 1
        
        if answer_data['is_correct']:
            session['correct_answers'] += 1
            session['current_streak'] += 1
        else:
            session['current_streak'] = 0
            
        session['peak_response_time'] = max(
            session['peak_response_time'], 
            answer_data['response_time']
        )
        
        # çµ±è¨ˆè¨ˆç®—
        accuracy_rate = session['correct_answers'] / session['questions_answered']
        session_duration = (datetime.now() - session['start_time']).total_seconds()
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çµ±è¨ˆé…ä¿¡
        stats_update = {
            'session_id': session_id,
            'progress': {
                'questions_answered': session['questions_answered'],
                'accuracy_rate': round(accuracy_rate * 100, 1),
                'current_streak': session['current_streak'],
                'session_duration': int(session_duration),
                'avg_response_time': round(
                    session_duration / session['questions_answered'], 1
                )
            },
            'insights': self.generate_real_time_insights(session, answer_data)
        }
        
        self.socketio.emit('progress_update', stats_update, 
                          room=f'user_{session["user_id"]}')
    
    def generate_real_time_insights(self, session: dict, latest_answer: dict) -> list:
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ"""
        insights = []
        
        # é€£ç¶šæ­£è§£ã‚¹ãƒˆãƒªãƒ¼ã‚¯
        if session['current_streak'] >= 5:
            insights.append({
                'type': 'achievement',
                'message': f'ğŸ”¥ {session["current_streak"]}å•é€£ç¶šæ­£è§£ä¸­ï¼',
                'priority': 'high'
            })
        
        # å›ç­”é€Ÿåº¦åˆ†æ
        if latest_answer['response_time'] < 30:
            insights.append({
                'type': 'performance',
                'message': 'âš¡ ç´ æ—©ã„å›ç­”ï¼ç†è§£åº¦ãŒé«˜ã¾ã£ã¦ã„ã¾ã™',
                'priority': 'medium'
            })
        elif latest_answer['response_time'] > 120:
            insights.append({
                'type': 'suggestion',
                'message': 'ğŸ¤” æ™‚é–“ã‚’ã‹ã‘ã¦è€ƒãˆã¾ã—ãŸã­ã€‚å¾©ç¿’ã‚’ãŠå‹§ã‚ã—ã¾ã™',
                'priority': 'medium'
            })
        
        # æ­£ç­”ç‡ãƒˆãƒ¬ãƒ³ãƒ‰
        accuracy = session['correct_answers'] / session['questions_answered']
        if accuracy >= 0.8:
            insights.append({
                'type': 'encouragement',
                'message': f'âœ¨ æ­£ç­”ç‡{accuracy*100:.0f}%ï¼é †èª¿ã§ã™',
                'priority': 'low'
            })
        elif accuracy < 0.6:
            insights.append({
                'type': 'guidance',
                'message': 'ğŸ“š åŸºç¤çŸ¥è­˜ã®ç¢ºèªã‚’ã—ã¦ã¿ã¾ã—ã‚‡ã†',
                'priority': 'high'
            })
        
        return insights

# WebSocket ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
@socketio.on('join_dashboard')
def handle_join_dashboard(data):
    user_id = data['user_id']
    join_room(f'user_{user_id}')
    
    # ç¾åœ¨ã®å­¦ç¿’çŠ¶æ³ã‚’é€ä¿¡
    current_stats = get_user_current_stats(user_id)
    emit('dashboard_init', current_stats)

@socketio.on('request_detailed_analysis')
def handle_detailed_analysis(data):
    user_id = data['user_id']
    period = data.get('period', 'week')  # day, week, month
    
    # è©³ç´°åˆ†æãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    analysis = generate_detailed_analysis(user_id, period)
    emit('detailed_analysis', analysis)
```

### ğŸŸ¡ é‡è¦åº¦ï¼šé«˜ï¼ˆ2-4é€±é–“å¾Œé–‹å§‹ï¼‰

#### **1.4 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–**
**å„ªå…ˆåº¦**: â˜…â˜…â˜…â˜…â˜† | **æœŸé–“**: 1-2é€±é–“ | **æŠ•è³‡**: ä½

```python
# security/enhanced_auth.py
from flask_jwt_extended import JWTManager, create_access_token, verify_jwt_in_request
import pyotp
import qrcode
from cryptography.fernet import Fernet

class EnhancedSecuritySystem:
    def __init__(self, app):
        self.app = app
        self.jwt = JWTManager(app)
        self.encryption_key = Fernet.generate_key()
        self.cipher = Fernet(self.encryption_key)
        
    def setup_2fa(self, user_id: int) -> dict:
        """2è¦ç´ èªè¨¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        secret = pyotp.random_base32()
        
        # QRã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        totp = pyotp.TOTP(secret)
        qr_uri = totp.provisioning_uri(
            name=f"user_{user_id}",
            issuer_name="IT Exam Learning System"
        )
        
        qr = qrcode.QRCode(version=1, box_size=10, border=5)
        qr.add_data(qr_uri)
        qr.make(fit=True)
        
        # æš—å·åŒ–ã—ã¦ä¿å­˜
        encrypted_secret = self.cipher.encrypt(secret.encode()).decode()
        
        return {
            'secret': encrypted_secret,
            'qr_code': qr.make_image(),
            'backup_codes': self.generate_backup_codes(user_id)
        }
    
    def verify_2fa(self, user_id: int, token: str) -> bool:
        """2FA ãƒˆãƒ¼ã‚¯ãƒ³æ¤œè¨¼"""
        # æš—å·åŒ–ã•ã‚ŒãŸç§˜å¯†éµå–å¾—
        encrypted_secret = self.get_user_2fa_secret(user_id)
        if not encrypted_secret:
            return False
            
        # å¾©å·åŒ–
        secret = self.cipher.decrypt(encrypted_secret.encode()).decode()
        
        # TOTPæ¤œè¨¼
        totp = pyotp.TOTP(secret)
        return totp.verify(token, valid_window=1)
    
    @staticmethod  
    def secure_session_management():
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†å¼·åŒ–"""
        @app.before_request
        def security_headers():
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼è¿½åŠ 
            response.headers['X-Content-Type-Options'] = 'nosniff'
            response.headers['X-Frame-Options'] = 'DENY'
            response.headers['X-XSS-Protection'] = '1; mode=block'
            response.headers['Strict-Transport-Security'] = 'max-age=31536000; includeSubDomains'
            
        @app.after_request
        def rotate_csrf_token(response):
            # CSRF ãƒˆãƒ¼ã‚¯ãƒ³ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
            if hasattr(g, 'csrf_token'):
                response.set_cookie('csrf_token', g.csrf_token, 
                                  secure=True, httponly=True, samesite='Strict')
            return response

# å®Ÿè£…ã‚¿ã‚¹ã‚¯
SECURITY_TASKS = [
    "âœ… 2è¦ç´ èªè¨¼ï¼ˆTOTPï¼‰å®Ÿè£…",
    "âœ… JWT ãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†ãƒ»ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³",
    "âœ… CSRF ä¿è­·å¼·åŒ–",
    "âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³å›ºå®šæ”»æ’ƒå¯¾ç­–",
    "âœ… SQL ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ç›£æŸ»",
    "âœ… XSS å¯¾ç­–ãƒ»å…¥åŠ›å€¤ã‚µãƒ‹ã‚¿ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"
]
```

#### **1.5 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**
**å„ªå…ˆåº¦**: â˜…â˜…â˜…â˜†â˜† | **æœŸé–“**: 1-2é€±é–“ | **æŠ•è³‡**: ä¸­

```python
# performance/optimization.py
from functools import wraps
import redis
import pickle
from typing import Any, Callable

class PerformanceOptimizer:
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
        self.cache_ttl = {
            'questions': 3600,      # 1æ™‚é–“
            'user_stats': 300,      # 5åˆ†
            'leaderboard': 600,     # 10åˆ†
            'analytics': 1800       # 30åˆ†
        }
    
    def intelligent_cache(self, cache_type: str, key_func: Callable = None):
        """ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ
                if key_func:
                    cache_key = f"{cache_type}:{key_func(*args, **kwargs)}"
                else:
                    cache_key = f"{cache_type}:{func.__name__}:{hash(str(args) + str(kwargs))}"
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
                cached_result = self.redis_client.get(cache_key)
                if cached_result:
                    return pickle.loads(cached_result)
                
                # é–¢æ•°å®Ÿè¡Œ
                result = func(*args, **kwargs)
                
                # çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆTTLè¨­å®šï¼‰
                ttl = self.cache_ttl.get(cache_type, 300)
                self.redis_client.setex(
                    cache_key, 
                    ttl, 
                    pickle.dumps(result)
                )
                
                return result
            return wrapper
        return decorator
    
    def database_query_optimization(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªæœ€é©åŒ–"""
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–
        optimization_queries = [
            "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_questions_category_difficulty ON questions(category, difficulty_level);",
            "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_learning_records_user_date ON learning_records(user_id, attempt_date);",
            "CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_sessions_user_active ON study_sessions(user_id, status) WHERE status = 'active';",
            
            # ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰
            """
            CREATE TABLE learning_records_2025 PARTITION OF learning_records
            FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');
            """,
            
            # ãƒãƒ†ãƒªã‚¢ãƒ©ã‚¤ã‚ºãƒ‰ãƒ“ãƒ¥ãƒ¼
            """
            CREATE MATERIALIZED VIEW user_daily_stats AS
            SELECT 
                user_id,
                DATE(attempt_date) as study_date,
                COUNT(*) as questions_answered,
                COUNT(*) FILTER (WHERE is_correct) as correct_answers,
                AVG(response_time) as avg_response_time
            FROM learning_records
            WHERE attempt_date >= CURRENT_DATE - INTERVAL '30 days'
            GROUP BY user_id, DATE(attempt_date);
            """
        ]
        
        return optimization_queries
    
    def memory_usage_optimization(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æœ€é©åŒ–"""
        
        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ—ãƒ¼ãƒ«
        class QuestionPool:
            def __init__(self, max_size: int = 1000):
                self.pool = []
                self.max_size = max_size
                
            def get_question(self, question_id: int):
                # ãƒ—ãƒ¼ãƒ«ã‹ã‚‰å–å¾—ã¾ãŸã¯æ–°è¦ä½œæˆ
                for q in self.pool:
                    if q.id == question_id:
                        return q
                        
                if len(self.pool) >= self.max_size:
                    self.pool.pop(0)  # LRU
                    
                question = self.load_from_db(question_id)
                self.pool.append(question)
                return question
        
        # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã—ãŸãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        def batch_process_questions(question_ids: list, batch_size: int = 100):
            """å¤§é‡å•é¡Œã®åŠ¹ç‡çš„å‡¦ç†"""
            for i in range(0, len(question_ids), batch_size):
                batch = question_ids[i:i + batch_size]
                yield self.load_questions_batch(batch)
                
        return QuestionPool(), batch_process_questions

# ä½¿ç”¨ä¾‹
optimizer = PerformanceOptimizer()

@optimizer.intelligent_cache('questions', lambda exam_type, category: f"{exam_type}_{category}")
def get_questions_by_category(exam_type: str, category: str):
    return db.query(Question).filter(
        Question.exam_type == exam_type,
        Question.category == category
    ).all()

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {}
        
    def measure_execution_time(self, func_name: str):
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                start_time = time.time()
                result = func(*args, **kwargs)
                execution_time = time.time() - start_time
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                if func_name not in self.metrics:
                    self.metrics[func_name] = []
                self.metrics[func_name].append(execution_time)
                
                # é–¾å€¤è¶…éæ™‚ã®ã‚¢ãƒ©ãƒ¼ãƒˆ
                if execution_time > 2.0:  # 2ç§’è¶…é
                    self.log_performance_issue(func_name, execution_time, args, kwargs)
                
                return result
            return wrapper
        return decorator
```

---

## ğŸ“‹ Phase 2: é«˜åº¦æ©Ÿèƒ½å®Ÿè£…ï¼ˆ6-8é€±é–“ï¼‰

### ğŸ”´ AIãƒ»æ©Ÿæ¢°å­¦ç¿’æ©Ÿèƒ½

#### **2.1 å­¦ç¿’æ¨å¥¨ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆå”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰**
**å„ªå…ˆåº¦**: â˜…â˜…â˜…â˜…â˜† | **æœŸé–“**: 3-4é€±é–“ | **æŠ•è³‡**: é«˜

```python
# ml_engine/recommendation_system.py
import numpy as np
import pandas as pd
from sklearn.decomposition import NMF
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler

class IntelligentRecommendationEngine:
    def __init__(self):
        self.model = None
        self.user_item_matrix = None
        self.item_features = None
        self.user_features = None
        
    def train_collaborative_filtering(self, learning_records: pd.DataFrame):
        """å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼-å•é¡Œãƒãƒˆãƒªãƒƒã‚¯ã‚¹ä½œæˆ
        self.user_item_matrix = learning_records.pivot_table(
            index='user_id',
            columns='question_id', 
            values='is_correct',
            fill_value=-1  # æœªå›ç­”ã¯-1
        )
        
        # æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œ
        filled_matrix = self.user_item_matrix.replace(-1, np.nan)
        filled_matrix = filled_matrix.fillna(filled_matrix.mean())
        
        # éè² å€¤è¡Œåˆ—åˆ†è§£
        self.model = NMF(n_components=50, random_state=42, max_iter=500)
        self.user_features = self.model.fit_transform(filled_matrix)
        self.item_features = self.model.components_
        
        # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è©•ä¾¡
        reconstructed = np.dot(self.user_features, self.item_features)
        mse = np.mean((filled_matrix.values - reconstructed) ** 2)
        print(f"Model MSE: {mse:.4f}")
        
    def recommend_questions(self, user_id: int, n_recommendations: int = 10, 
                          filters: dict = None) -> list:
        """å€‹äººåŒ–å•é¡Œæ¨å¥¨"""
        
        if user_id not in self.user_item_matrix.index:
            return self._cold_start_recommendations(n_recommendations, filters)
        
        user_idx = self.user_item_matrix.index.get_loc(user_id)
        user_vector = self.user_features[user_idx]
        
        # å…¨å•é¡Œã‚¹ã‚³ã‚¢è¨ˆç®—
        scores = np.dot(user_vector, self.item_features)
        
        # æ—¢å›ç­”å•é¡Œé™¤å¤–
        answered_questions = self.user_item_matrix.iloc[user_idx]
        answered_mask = answered_questions != -1
        scores[answered_mask] = -np.inf
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
        if filters:
            scores = self._apply_filters(scores, filters)
        
        # ãƒˆãƒƒãƒ—Næ¨å¥¨
        top_indices = np.argsort(scores)[-n_recommendations:][::-1]
        question_ids = self.user_item_matrix.columns[top_indices].tolist()
        
        # æ¨å¥¨ç†ç”±ä»˜ã
        recommendations = []
        for i, qid in enumerate(question_ids):
            recommendations.append({
                'question_id': qid,
                'score': float(scores[top_indices[i]]),
                'reason': self._generate_recommendation_reason(user_id, qid),
                'confidence': self._calculate_confidence(user_id, qid)
            })
            
        return recommendations
    
    def _generate_recommendation_reason(self, user_id: int, question_id: int) -> str:
        """æ¨å¥¨ç†ç”±ç”Ÿæˆ"""
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        user_performance = self.analyze_user_performance(user_id)
        question_info = self.get_question_info(question_id)
        
        reasons = []
        
        # å¼±ç‚¹åˆ†é‡ã«è©²å½“
        if question_info['category'] in user_performance['weak_areas']:
            reasons.append(f"{question_info['category']}åˆ†é‡ã®å¼·åŒ–ã«æœ€é©")
            
        # é©åˆ‡ãªé›£æ˜“åº¦
        if abs(question_info['difficulty'] - user_performance['skill_level']) <= 0.5:
            reasons.append("ç¾åœ¨ã®ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«ã«é©ã—ãŸé›£æ˜“åº¦")
            
        # é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé«˜è©•ä¾¡
        similar_users_score = self.get_similar_users_performance(user_id, question_id)
        if similar_users_score > 0.7:
            reasons.append("é¡ä¼¼ãƒ¬ãƒ™ãƒ«ã®å­¦ç¿’è€…ãŒé«˜ã„æˆæœã‚’ä¸Šã’ã¦ã„ã¾ã™")
        
        return "ã€".join(reasons) if reasons else "å­¦ç¿’åŠ¹æœãŒæœŸå¾…ã§ãã¾ã™"

# å®Ÿè£…ã‚¿ã‚¹ã‚¯
ML_TASKS = [
    "âœ… å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹æ¨å¥¨ã‚¨ãƒ³ã‚¸ãƒ³",
    "âœ… ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°", 
    "âœ… ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¨å¥¨ã‚·ã‚¹ãƒ†ãƒ ",
    "âœ… æ¨å¥¨ç²¾åº¦è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆA/Bãƒ†ã‚¹ãƒˆï¼‰",
    "âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨å¥¨æ›´æ–°",
    "âœ… ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå•é¡Œå¯¾ç­–"
]
```

#### **2.2 é©å¿œçš„é›£æ˜“åº¦èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ **
**å„ªå…ˆåº¦**: â˜…â˜…â˜…â˜…â˜† | **æœŸé–“**: 2-3é€±é–“ | **æŠ•è³‡**: ä¸­

```python
# ml_engine/adaptive_difficulty.py
class AdaptiveDifficultySystem:
    def __init__(self):
        self.elo_k_factor = 32
        self.default_rating = 1200
        self.difficulty_bounds = (800, 1600)  # é›£æ˜“åº¦ç¯„å›²
        
    def update_question_difficulty(self, question_id: int, user_responses: list):
        """å•é¡Œé›£æ˜“åº¦ã®å‹•çš„æ›´æ–°"""
        
        current_difficulty = self.get_current_difficulty(question_id)
        
        for response in user_responses:
            user_skill = self.get_user_skill_rating(response['user_id'])
            
            # æœŸå¾…æ­£ç­”ç‡è¨ˆç®—ï¼ˆEloã‚·ã‚¹ãƒ†ãƒ ï¼‰
            expected_score = 1 / (1 + 10**((current_difficulty - user_skill) / 400))
            actual_score = 1 if response['is_correct'] else 0
            
            # é›£æ˜“åº¦æ›´æ–°
            k_factor = self._calculate_k_factor(question_id)
            difficulty_change = k_factor * (actual_score - expected_score)
            current_difficulty -= difficulty_change  # æ­£è§£å¤šã„â†’é›£æ˜“åº¦ä¸‹ã’ã‚‹
            
            # å¢ƒç•Œå€¤åˆ¶é™
            current_difficulty = max(self.difficulty_bounds[0], 
                                   min(self.difficulty_bounds[1], current_difficulty))
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
        self.update_question_difficulty_db(question_id, current_difficulty)
        
        return current_difficulty
    
    def select_optimal_difficulty(self, user_id: int, category: str, 
                                session_context: dict) -> float:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æœ€é©ãªé›£æ˜“åº¦é¸æŠ"""
        
        user_skill = self.get_user_skill_rating(user_id)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—åˆ¥èª¿æ•´
        if session_context.get('type') == 'challenge':
            # ãƒãƒ£ãƒ¬ãƒ³ã‚¸ãƒ¢ãƒ¼ãƒ‰ï¼šå°‘ã—é›£ã—ã‚
            target_difficulty = user_skill + 100
        elif session_context.get('type') == 'review':
            # å¾©ç¿’ãƒ¢ãƒ¼ãƒ‰ï¼šå°‘ã—æ˜“ã—ã‚
            target_difficulty = user_skill - 50
        else:
            # é€šå¸¸å­¦ç¿’ï¼šåŒãƒ¬ãƒ™ãƒ«
            target_difficulty = user_skill
            
        # åˆ†é‡åˆ¥èª¿æ•´
        category_modifier = self.get_category_skill_modifier(user_id, category)
        target_difficulty += category_modifier
        
        # å­¦ç¿’åŠ¹æœæœ€é©åŒ–ï¼ˆZone of Proximal Developmentï¼‰
        optimal_range = (target_difficulty - 100, target_difficulty + 100)
        
        return optimal_range
    
    def predict_success_probability(self, user_id: int, question_id: int) -> float:
        """æˆåŠŸç¢ºç‡äºˆæ¸¬"""
        
        user_skill = self.get_user_skill_rating(user_id)
        question_difficulty = self.get_current_difficulty(question_id)
        
        # åŸºæœ¬ç¢ºç‡ï¼ˆEloã‚·ã‚¹ãƒ†ãƒ ï¼‰
        base_probability = 1 / (1 + 10**((question_difficulty - user_skill) / 400))
        
        # å€‹äººçš„è¦å› ã«ã‚ˆã‚‹èª¿æ•´
        personal_factors = self._calculate_personal_factors(user_id, question_id)
        
        # æœ€çµ‚ç¢ºç‡
        final_probability = base_probability * personal_factors['multiplier']
        
        return max(0.01, min(0.99, final_probability))  # 1-99%ã«åˆ¶é™
    
    def _calculate_personal_factors(self, user_id: int, question_id: int) -> dict:
        """å€‹äººçš„è¦å› è¨ˆç®—"""
        
        factors = {'multiplier': 1.0, 'reasons': []}
        
        # æœ€è¿‘ã®å­¦ç¿’ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        recent_performance = self.get_recent_performance(user_id, days=7)
        if recent_performance['accuracy'] > 0.8:
            factors['multiplier'] *= 1.1
            factors['reasons'].append('æœ€è¿‘ã®æˆç¸¾ãŒè‰¯ã„')
        elif recent_performance['accuracy'] < 0.6:
            factors['multiplier'] *= 0.9
            factors['reasons'].append('æœ€è¿‘è‹¦æˆ¦ã—ã¦ã„ã‚‹')
            
        # åˆ†é‡ã®å¾—æ„ãƒ»ä¸å¾—æ„
        question_category = self.get_question_category(question_id)
        category_strength = self.get_category_strength(user_id, question_category)
        
        if category_strength > 0.2:  # å¾—æ„åˆ†é‡
            factors['multiplier'] *= 1.15
            factors['reasons'].append(f'{question_category}ãŒå¾—æ„')
        elif category_strength < -0.2:  # è‹¦æ‰‹åˆ†é‡
            factors['multiplier'] *= 0.85
            factors['reasons'].append(f'{question_category}ãŒè‹¦æ‰‹')
            
        # å­¦ç¿’æ™‚é–“å¸¯
        current_hour = datetime.now().hour
        optimal_hours = self.get_user_optimal_hours(user_id)
        if current_hour in optimal_hours:
            factors['multiplier'] *= 1.05
            factors['reasons'].append('é›†ä¸­ã—ã‚„ã™ã„æ™‚é–“å¸¯')
            
        return factors
```

### ğŸŸ¡ ã‚·ã‚¹ãƒ†ãƒ æ‹¡å¼µæ©Ÿèƒ½

#### **2.3 ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åˆ†é›¢**
**å„ªå…ˆåº¦**: â˜…â˜…â˜…â˜†â˜† | **æœŸé–“**: 4-5é€±é–“ | **æŠ•è³‡**: é«˜

```yaml
# microservices/docker-compose.yml
version: '3.8'

services:
  # API Gateway
  api-gateway:
    build: ./api-gateway
    ports:
      - "80:8080"
    environment:
      - KONG_DATABASE=off
      - KONG_DECLARATIVE_CONFIG=/kong/declarative/kong.yml
    volumes:
      - ./api-gateway/kong.yml:/kong/declarative/kong.yml

  # User Service
  user-service: 
    build: ./services/user-service
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres-user:5432/users
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - postgres-user
      - redis

  # Learning Service
  learning-service:
    build: ./services/learning-service
    environment:
      - DATABASE_URL=postgresql://learning:pass@postgres-learning:5432/learning
      - REDIS_URL=redis://redis:6379/1
      - USER_SERVICE_URL=http://user-service:8000
    depends_on:
      - postgres-learning
      - redis
      - user-service

  # Question Service
  question-service:
    build: ./services/question-service
    environment:
      - DATABASE_URL=postgresql://questions:pass@postgres-questions:5432/questions
      - ELASTICSEARCH_URL=http://elasticsearch:9200
    depends_on:
      - postgres-questions
      - elasticsearch

  # Analytics Service  
  analytics-service:
    build: ./services/analytics-service
    environment:
      - DATABASE_URL=postgresql://analytics:pass@postgres-analytics:5432/analytics
      - TIMESERIES_DB_URL=http://influxdb:8086
    depends_on:
      - postgres-analytics
      - influxdb

  # Databases
  postgres-user:
    image: postgres:15
    environment:
      POSTGRES_DB: users
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    volumes:
      - user_data:/var/lib/postgresql/data

  postgres-learning:
    image: postgres:15
    environment:
      POSTGRES_DB: learning
      POSTGRES_USER: learning
      POSTGRES_PASSWORD: pass
    volumes:
      - learning_data:/var/lib/postgresql/data

  # Supporting Services
  redis:
    image: redis:alpine
    volumes:
      - redis_data:/data

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

volumes:
  user_data:
  learning_data:
  redis_data:
  elasticsearch_data:
```

---

## ğŸ“‹ Phase 3: æ¬¡ä¸–ä»£ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼ˆ8-12é€±é–“ï¼‰

### ğŸ”´ ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æ‹¡å¼µ

#### **3.1 å¤šè¨€èªãƒ»å›½éš›åŒ–å¯¾å¿œ**
**å„ªå…ˆåº¦**: â˜…â˜…â˜†â˜†â˜† | **æœŸé–“**: 3-4é€±é–“ | **æŠ•è³‡**: ä¸­

```python
# i18n/internationalization.py
from flask_babel import Babel, gettext, ngettext
import json

class InternationalizationSystem:
    def __init__(self, app):
        self.app = app
        self.babel = Babel(app)
        self.supported_languages = ['ja', 'en', 'ko', 'zh-CN']
        
    def setup_language_detection(self):
        @self.babel.localeselector
        def get_locale():
            # 1. URL ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            if request.args.get('lang'):
                session['language'] = request.args.get('lang')
                
            # 2. ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜è¨€èª
            if 'language' in session:
                return session['language']
                
            # 3. ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š
            if current_user.is_authenticated:
                return current_user.preferred_language
                
            # 4. ãƒ–ãƒ©ã‚¦ã‚¶è¨­å®š
            return request.accept_languages.best_match(self.supported_languages) or 'ja'
    
    def localize_questions(self, questions: list, target_language: str) -> list:
        """å•é¡Œã®å¤šè¨€èªåŒ–"""
        
        if target_language == 'ja':
            return questions  # ã‚ªãƒªã‚¸ãƒŠãƒ«æ—¥æœ¬èª
            
        localized_questions = []
        
        for question in questions:
            # ç¿»è¨³ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
            cache_key = f"question_{question['id']}_{target_language}"
            cached_translation = self.get_translation_cache(cache_key)
            
            if cached_translation:
                localized_questions.append(cached_translation)
                continue
                
            # AIç¿»è¨³å®Ÿè¡Œ
            translated_question = {
                'id': question['id'],
                'question_text': self.translate_text(question['question_text'], target_language),
                'choices': [self.translate_text(choice, target_language) for choice in question['choices']],
                'explanation': self.translate_text(question['explanation'], target_language),
                'category': self.translate_category(question['category'], target_language),
                'original_language': 'ja'
            }
            
            # ç¿»è¨³å“è³ªãƒã‚§ãƒƒã‚¯
            quality_score = self.assess_translation_quality(question, translated_question)
            if quality_score < 0.8:
                # å“è³ªãŒä½ã„å ´åˆã¯äººæ‰‹ç¿»è¨³ãƒ•ãƒ©ã‚°
                translated_question['needs_human_review'] = True
                
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
            self.save_translation_cache(cache_key, translated_question)
            localized_questions.append(translated_question)
            
        return localized_questions

# å®Ÿè£…ã‚¿ã‚¹ã‚¯
I18N_TASKS = [
    "âœ… Flask-Babelçµ±åˆãƒ»åŸºæœ¬å¤šè¨€èªåŒ–",
    "âœ… AIç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ ï¼ˆDeepL/Google Translateï¼‰", 
    "âœ… ç¿»è¨³å“è³ªç®¡ç†ãƒ»äººæ‰‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼",
    "âœ… æ–‡åŒ–çš„é©å¿œï¼ˆè©¦é¨“åˆ¶åº¦ã®é•ã„å¯¾å¿œï¼‰",
    "âœ… å¤šè¨€èªSEOå¯¾å¿œ",
    "âœ… RTLè¨€èªå¯¾å¿œï¼ˆã‚¢ãƒ©ãƒ“ã‚¢èªç­‰ï¼‰"
]
```

#### **3.2 ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªé–‹ç™º**  
**å„ªå…ˆåº¦**: â˜…â˜…â˜†â˜†â˜† | **æœŸé–“**: 6-8é€±é–“ | **æŠ•è³‡**: é«˜

```typescript
// mobile_app/src/services/LearningService.ts
import { ApiService } from './ApiService';
import { StorageService } from './StorageService';

interface StudySession {
  id: string;
  questions: Question[];
  currentIndex: number;
  startTime: Date;
  isOffline: boolean;
}

export class LearningService {
  private apiService = new ApiService();
  private storageService = new StorageService();
  
  async startStudySession(preferences: StudyPreferences): Promise<StudySession> {
    try {
      // ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ™‚ã¯APIã‹ã‚‰å–å¾—
      const sessionData = await this.apiService.createStudySession(preferences);
      
      // ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œã§ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜
      await this.storageService.saveSession(sessionData);
      
      return {
        ...sessionData,
        startTime: new Date(),
        isOffline: false
      };
      
    } catch (error) {
      // ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ™‚ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨
      console.log('ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ');
      return this.createOfflineSession(preferences);
    }
  }
  
  async submitAnswer(sessionId: string, questionId: string, answer: number): Promise<AnswerResult> {
    const answerData = {
      sessionId,
      questionId, 
      answer,
      responseTime: this.calculateResponseTime(),
      timestamp: new Date().toISOString()
    };
    
    try {
      // ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æå‡º
      const result = await this.apiService.submitAnswer(answerData);
      
      // ãƒ­ãƒ¼ã‚«ãƒ«åŒæœŸ
      await this.storageService.syncAnswer(answerData, result);
      
      return result;
      
    } catch (error) {
      // ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ™‚ã¯ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜
      const offlineResult = await this.processOfflineAnswer(answerData);
      
      // å¾Œã§åŒæœŸã™ã‚‹ãŸã‚ã«ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
      await this.storageService.addToSyncQueue(answerData);
      
      return offlineResult;
    }
  }
  
  private async createOfflineSession(preferences: StudyPreferences): Promise<StudySession> {
    // ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜æ¸ˆã¿ã®å•é¡Œã‹ã‚‰é¸å‡º
    const cachedQuestions = await this.storageService.getCachedQuestions(preferences);
    
    if (cachedQuestions.length === 0) {
      throw new Error('ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å­¦ç¿’ç”¨ã®å•é¡Œãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“');
    }
    
    return {
      id: `offline_${Date.now()}`,
      questions: cachedQuestions.slice(0, preferences.questionCount),
      currentIndex: 0,
      startTime: new Date(),
      isOffline: true
    };
  }
}

// ãƒ—ãƒƒã‚·ãƒ¥é€šçŸ¥ã‚µãƒ¼ãƒ“ã‚¹
export class NotificationService {
  async scheduleStudyReminder(userId: string, preferences: NotificationPreferences) {
    const notifications = [
      {
        id: 'daily_study',
        title: 'ä»Šæ—¥ã®å­¦ç¿’ã¯ã„ã‹ãŒã§ã™ã‹ï¼Ÿ',
        body: 'ç¶™ç¶šçš„ãªå­¦ç¿’ã§åˆæ ¼ã«è¿‘ã¥ãã¾ã—ã‚‡ã†ï¼',
        schedule: preferences.dailyReminderTime,
        repeat: 'daily'
      },
      {
        id: 'streak_motivation',
        title: `ğŸ”¥ ${await this.getCurrentStreak(userId)}æ—¥é€£ç¶šå­¦ç¿’ä¸­ï¼`,
        body: 'ã‚¹ãƒˆãƒªãƒ¼ã‚¯ã‚’ç¶™ç¶šã—ã¾ã—ã‚‡ã†',
        schedule: preferences.streakReminderTime,
        repeat: 'daily',
        condition: 'has_active_streak'
      }
    ];
    
    for (const notification of notifications) {
      await this.scheduleLocalNotification(notification);
    }
  }
}
```

---

## ğŸ¯ æœ€çµ‚ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ãƒ»å®Ÿè¡Œè¨ˆç”»

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"content": "\u73fe\u72b6\u5206\u6790\u3068\u30e6\u30fc\u30b6\u30fc\u30cb\u30fc\u30ba\u8abf\u67fb", "status": "completed", "priority": "high", "id": "1"}, {"content": "\u6a5f\u80fd\u8981\u4ef6\u306e\u8a73\u7d30\u5b9a\u7fa9", "status": "completed", "priority": "high", "id": "2"}, {"content": "\u6280\u8853\u8981\u4ef6\u3068\u5236\u7d04\u4e8b\u9805\u306e\u6574\u7406", "status": "completed", "priority": "high", "id": "3"}, {"content": "UI/UX\u6539\u5584\u63d0\u6848", "status": "completed", "priority": "medium", "id": "4"}, {"content": "\u30b7\u30b9\u30c6\u30e0\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u5f37\u5316\u6848", "status": "completed", "priority": "medium", "id": "5"}, {"content": "\u958b\u767a\u30fb\u904b\u7528\u6539\u5584\u63d0\u6848", "status": "completed", "priority": "medium", "id": "6"}, {"content": "\u5b9f\u88c5\u512a\u5148\u5ea6\u3068\u30ed\u30fc\u30c9\u30de\u30c3\u30d7\u4f5c\u6210", "status": "completed", "priority": "high", "id": "7"}]